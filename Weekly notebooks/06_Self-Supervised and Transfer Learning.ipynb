{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffd2760e",
   "metadata": {},
   "source": [
    "# 6. Self-supervised learning\n",
    "\n",
    "Welcome to this module's notebook where we dive into the fascinating realm of self-supervised learning, one of our groups favorite topics! While transfer learning stands as a prominent topic in machine learning, implementation-wise it is not as interesting as self-supervised learning.\n",
    "\n",
    "In this notebook, we've chosen to delve into the 'Bootstrap Your Own Latent space' (BYOL) method. Traditionally, self-supervised learning methods have been associated with vast datasets and meticulous batch size considerations, often limiting experimentation to tech giants like Google, Meta, and others. However, in this exploration, we aim to break down these barriers, demonstrating that even with limited resources, one can harness the power of unlabeled data to train models effectively.\n",
    "\n",
    "Since we know everyone is working hard on the Final assignments this notebook is limited in terms of implementation exercises, however, there are some question that maybe help you understand some general idea's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca77aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from lightly.loss import NegativeCosineSimilarity\n",
    "from lightly.models.modules import BYOLPredictionHead, BYOLProjectionHead\n",
    "from lightly.models.utils import deactivate_requires_grad, update_momentum\n",
    "from lightly.transforms.byol_transform import (\n",
    "    BYOLTransform,\n",
    "    BYOLView1Transform,\n",
    "    BYOLView2Transform,\n",
    ")\n",
    "from lightly.utils.scheduler import cosine_schedule\n",
    "import os\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_DIR = os.path.join(os.getenv('TEACHER_DIR'), 'JHS_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7068f710",
   "metadata": {},
   "source": [
    "If you check the lecture slides, you'll notice that BYOL necessitates the use of two different augmented versions of a single image. Take the opportunity to implement this requirement, and carefully consider the transformations you'll use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e40d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two crop transform\n",
    "contrastive_transform = transforms.Compose([\n",
    "                                   #implement the correct augmentations\n",
    "                                   transforms.ToTensor(),\n",
    "                                   ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "                                   #leave this as it is\n",
    "                                   transforms.ToTensor(),\n",
    "                                   ])\n",
    "\n",
    "class TwoCropTransform:\n",
    "    \"\"\"Create two crops of the same image\"\"\"\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return [self.transform(x), self.transform(x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb8705b",
   "metadata": {},
   "source": [
    "We will use the MNIST training dataset for our self-supervised learning training. We will use the test set for evaluation what our model has learned without any labels. \n",
    "\n",
    "**Q1.** What will happen if you keep your augmentations to easy?\n",
    "\n",
    "**Q2.** What happens to your model if you include a specific augmentation like e.g. rotation or [color jitter](https://pytorch.org/vision/main/generated/torchvision.transforms.ColorJitter.html)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b7d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We disable resizing and gaussian blur for cifar10.\n",
    "dataset = torchvision.datasets.MNIST(\n",
    "    DATA_DIR, download=False, train=True, transform=TwoCropTransform(contrastive_transform)\n",
    ")\n",
    "\n",
    "testdata = torchvision.datasets.MNIST(\n",
    "    DATA_DIR, download=False, train=False, transform=test_transform\n",
    ")\n",
    "\n",
    "# Create a subset of the training dataset containing only the first 1000 images\n",
    "subset_indices = range(1000)\n",
    "testdata = Subset(testdata, subset_indices)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=24,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=1,\n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testdata,\n",
    "    batch_size=24,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=1,\n",
    ")\n",
    "\n",
    "# visualize some examples images\n",
    "def visualize_augmented_images(dataset, indices):\n",
    "    fig, axes = plt.subplots(len(indices), 2, figsize=(10, 20))\n",
    "\n",
    "    for i, index in enumerate(indices):\n",
    "        image, _ = dataset[index]\n",
    "\n",
    "        # Plot the original image\n",
    "        axes[i, 0].imshow(image[0].squeeze(), cmap='gray')\n",
    "        axes[i, 0].set_title(f'Augmented Image 1')\n",
    "\n",
    "        # Plot the augmented image\n",
    "        axes[i, 1].imshow(image[1].squeeze(), cmap='gray')\n",
    "        axes[i, 1].set_title(f'Augmented Image 2')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Example usage:\n",
    "indices_to_visualize = range(4)\n",
    "visualize_augmented_images(dataset, indices_to_visualize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b251cc",
   "metadata": {},
   "source": [
    "We have already implemented this part for you, however it is important to understand the goal of the projection head.\n",
    "\n",
    "**Q3.** Why do we add an extra prediction head on top of the student network?\n",
    "\n",
    "**Q4.** What is the function of the projection head?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bc7927",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BYOL(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = backbone\n",
    "        self.projection_head = BYOLProjectionHead(512, 1024, 256)\n",
    "        self.prediction_head = BYOLPredictionHead(256, 1024, 256)\n",
    "\n",
    "        self.backbone_momentum = copy.deepcopy(self.backbone)\n",
    "        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
    "\n",
    "        deactivate_requires_grad(self.backbone_momentum)\n",
    "        deactivate_requires_grad(self.projection_head_momentum)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.projection_head(y)\n",
    "        p = self.prediction_head(z)\n",
    "        return p\n",
    "\n",
    "    def forward_momentum(self, x):\n",
    "        y = self.backbone_momentum(x).flatten(start_dim=1)\n",
    "        z = self.projection_head_momentum(y)\n",
    "        z = z.detach()\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6415925",
   "metadata": {},
   "source": [
    "Alright, let's start training! If you observe a decrease in your loss value, feel free to take a moment to relax. Training may require some time to complete...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61545b35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet = torchvision.models.resnet18(weights=False)\n",
    "resnet.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) # change first layer of resnet to one channel\n",
    "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "model = BYOL(backbone)\n",
    "criterion = NegativeCosineSimilarity()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.06)\n",
    "\n",
    "epochs = 5\n",
    "print_interval = 50\n",
    "total_steps = len(dataloader)\n",
    "\n",
    "print(\"Starting Training\")\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    momentum_val = cosine_schedule(epoch, epochs, 0.996, 1)\n",
    "    for i, batch in enumerate(dataloader, 0):\n",
    "        x0, x1 = batch[0]\n",
    "        update_momentum(model.backbone, model.backbone_momentum, m=momentum_val)\n",
    "        update_momentum(model.projection_head, model.projection_head_momentum, m=momentum_val)\n",
    "        \n",
    "        x0 = x0\n",
    "        x1 = x1\n",
    "        \n",
    "        \"\"\"Implement BYOL\"\"\"\n",
    "        p0 = model(x0)\n",
    "        z0 = model.forward_momentum(x0)\n",
    "        p1 = model(x1)\n",
    "        z1 = model.forward_momentum(x1)\n",
    "        loss = 1 + (0.5 * (criterion(p0, z1) + criterion(p1, z0)))\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (i + 1) % print_interval == 0:\n",
    "            average_loss = running_loss / print_interval\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Step [{i + 1}/{total_steps}], Loss: {average_loss:.4f}')\n",
    "            running_loss = 0.0\n",
    "               \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    torch.save(model.state_dict(), 'byol_model_epoch_{}.pth'.format(epoch+1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f8c71d",
   "metadata": {},
   "source": [
    "Okay after the training is done, lets see if the model learned anything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4827f0ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_path_prefix = \"byol_model_epoch_\"\n",
    "\n",
    "# Iterate through the first 5 epochs\n",
    "for epoch_nb in range(0, 6):\n",
    "    # Load the model for the current epoch\n",
    "    resnet = torchvision.models.resnet18(weights=False)\n",
    "    resnet.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) # change first layer of resnet to one channel\n",
    "    backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "    model = BYOL(backbone)\n",
    "    model_path = model_path_prefix + str(epoch_nb) + \".pth\"\n",
    "    if epoch_nb != 0:\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        \n",
    "    model.eval()\n",
    "\n",
    "    # Extract features from the dataset\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            features = model.backbone(images).squeeze()\n",
    "            features_list.append(features)\n",
    "            labels_list.append(labels)\n",
    "\n",
    "    features = torch.cat(features_list, dim=0).numpy()\n",
    "    labels = torch.cat(labels_list, dim=0).numpy()\n",
    "    \n",
    "\n",
    "    # Perform t-SNE dimensionality reduction\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    tsne_features = tsne.fit_transform(features)\n",
    "\n",
    "    # Plot t-SNE visualization for the current epoch\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(10):\n",
    "        indices = labels == i\n",
    "        plt.scatter(tsne_features[indices, 0], tsne_features[indices, 1], label=str(i), s=10)\n",
    "    plt.title(f't-SNE Visualization of MNIST Features (Epoch {epoch_nb})')\n",
    "    plt.xlabel('t-SNE Component 1')\n",
    "    plt.ylabel('t-SNE Component 2')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63aaf93",
   "metadata": {},
   "source": [
    "From this visualization it is clear that the model can already group certain digits in the MNIST dataset, without being trained with the labels!\n",
    "\n",
    "**Q5.** What are the primary advantages of utilizing the weights acquired through self-supervised learning when applied to a downstream task? \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
